{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82fab3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TC-CLIP Inference Demo for Custom Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd42d5-8cbc-4a1d-80a2-0ed6191effbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SETUP STUFF (RUN ONLY ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7751d900-d54d-455a-8b6a-48eb786cfe4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  4 13:49:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 556.35                 Driver Version: 556.35         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro P2000                 WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   54C    P8             N/A / ERR!  |    2528MiB /   4096MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      5072    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     11584    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     16548    C+G   ...am Files\\CONEXANT\\Flow\\FlowTray.exe      N/A      |\n",
      "|    0   N/A  N/A     16604      C   C:\\Users\\anaba\\anaconda3\\python.exe         N/A      |\n",
      "|    0   N/A  N/A     29076      C   C:\\Users\\anaba\\anaconda3\\python.exe         N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check NVIDIA driver\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c30a17e-9345-4888-a2ae-8826043254d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (2449.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anaba\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# Get correct version of torch\n",
    "!pip uninstall torch torchvision torchaudio -y \n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25fc73cc-456e-4452-97c9-d2979bca7009",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 12.1\n",
      "cuDNN Version: 90100\n",
      "Torch Version: 2.5.1+cu121\n",
      "True\n",
      "1\n",
      "Quadro P2000\n"
     ]
    }
   ],
   "source": [
    "# Verify torch installation\n",
    "\n",
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.device_count())  # Should return a positive number\n",
    "print(torch.cuda.get_device_name(0))  # Should print your GPU model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c4d42-3693-45ad-ba64-f8e48c159dac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Verify Cuda installed, make sure to restart notebook if the code below doesn't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "096c7b03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rustc 1.85.0 (4d91de4e4 2025-02-17)\n"
     ]
    }
   ],
   "source": [
    "!rustc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3bffa9-cfab-4025-a747-0a53f16550ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b23f9-2ae2-4041-a24d-3f93a4f437df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If the command above doesnt work, you need to install rust https://www.rust-lang.org/tools/install.  \n",
    "Download rustup-init.exe (64-bit) + run exe  \n",
    "Restart Jupyter, run command below to check versions.  \n",
    "Try installing `timm` again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce980a67-afa9-427b-b6cf-fdb9b7fd872a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rustc 1.85.0 (4d91de4e4 2025-02-17)\n",
      "cargo 1.85.0 (d73d2caf9 2024-12-31)\n"
     ]
    }
   ],
   "source": [
    "!rustc --version\n",
    "!cargo --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f676a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install hydra-core\n",
    "!pip install omegaconf\n",
    "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0/index.html\n",
    "!pip install einops\n",
    "!pip install ftfy\n",
    "!pip install termcolor\n",
    "!pip install decord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37e892",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set model path, custom video path, class names. (Run every time below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b539e8ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Change to your settings ###\n",
    "output=\"C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/inference\"\n",
    "tc_clip_model_path = \"C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/zero_shot_k400_tc_clip.pth\"   # Your pretrained model saved path\n",
    "class_names = ['dancing', 'jumping', 'kicking', 'kneeling', 'punching', 'running', 'throwing', 'walking']  # Class names\n",
    "\n",
    "parent_folder=\"C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/\"\n",
    "video_path = parent_folder + \"20221011_1_250_batch01hand_closeup_suburb_d_mp4/walking/seq_000001.mp4\" # TODO: Update custom video path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8aa680-f90a-49d4-864e-220f09da1472",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## No need to change below codes, just run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8245b63a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from datasets.pipeline import Compose\n",
    "from trainers.build_trainer import returnCLIP\n",
    "from utils.logger import create_logger\n",
    "from utils.print_utils import colorstr\n",
    "from utils.tools import load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb1a66",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Init configs and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ec10eb46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Hydra configs\n",
    "overrides = [\n",
    "    f\"output={output}\",\n",
    "    \"eval=test\",\n",
    "    \"trainer=tc_clip\",\n",
    "    f\"resume={tc_clip_model_path}\"\n",
    "]\n",
    "\n",
    "# Initialize Hydra with config path\n",
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    config = compose(config_name=\"zero_shot.yaml\", overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "748d8d90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[03-04 13:59:51 TCCLIP]\u001B[0m\u001B[33m(3979588942.py 9)\u001B[0m: INFO working dir: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/inference\n"
     ]
    }
   ],
   "source": [
    "# Init settings\n",
    "OmegaConf.set_struct(config, False)  # Needed to add fields at runtime below\n",
    "\n",
    "# Define working dir\n",
    "Path(config.output).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Logger\n",
    "logger = create_logger(output_dir=config.output, dist_rank=0, name=f\"{config.trainer_name}\")\n",
    "logger.info(f\"working dir: {config.output}\")\n",
    "\n",
    "# Whether to use pytorch or apex amp\n",
    "major, minor = int(torch.__version__.split('.')[0]), int(torch.__version__.split('.')[1])\n",
    "config.use_torch_amp = (major >= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9454e3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build model & load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a429597c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[03-04 13:59:51 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 56)\u001B[0m: INFO Loading CLIP (backbone: ViT-B/16)\n",
      "Using spatial positional embedding\n",
      "Weights not found for some missing keys:  ['visual.transformer.resblocks.1.attn.local_global_bias_table', 'visual.transformer.resblocks.2.attn.local_global_bias_table', 'visual.transformer.resblocks.3.attn.local_global_bias_table', 'visual.transformer.resblocks.4.attn.local_global_bias_table', 'visual.transformer.resblocks.5.attn.local_global_bias_table', 'visual.transformer.resblocks.6.attn.local_global_bias_table', 'visual.transformer.resblocks.7.attn.local_global_bias_table', 'visual.transformer.resblocks.8.attn.local_global_bias_table', 'visual.transformer.resblocks.9.attn.local_global_bias_table', 'visual.transformer.resblocks.10.attn.local_global_bias_table', 'visual.transformer.resblocks.11.attn.local_global_bias_table']\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 59)\u001B[0m: INFO \u001B[34m\u001B[1mBuilding TCCLIP\u001B[0m\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip_prompt_learner.py 54)\u001B[0m: INFO Video-conditional prompt learning\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip_prompt_learner.py 55)\u001B[0m: INFO Initial context: \"a photo of a\"\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip_prompt_learner.py 56)\u001B[0m: INFO Number of learnable text prompt vectors: 4\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip_text_encoder.py 96)\u001B[0m: INFO Copy CLIP transformer 11th layer weights to prompt generation layer\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip_text_encoder.py 106)\u001B[0m: INFO Prompt generation level: [11]\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip_text_encoder.py 107)\u001B[0m: INFO Prompt generation stop grad: True\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(tc_clip.py 27)\u001B[0m: INFO Using context tokens from vision layer [11]\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 97)\u001B[0m: INFO ----------------------------------------------------\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 98)\u001B[0m: INFO Freezed Parameters\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 102)\u001B[0m: INFO ----------------------------------------------------\n",
      "\u001B[32m[03-04 13:59:55 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 105)\u001B[0m: INFO Number of Parameters: 127.5M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TCCLIP(\n",
       "  (prompt_learner): VPPromptLearner()\n",
       "  (image_encoder): TCVisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TCAttentionBlock(\n",
       "          (attn): TCAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (text_encoder): VPTextEncoder(\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (prompt_generation_layer): ModuleList(\n",
       "      (0): PromptGenerationLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_1_kv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = returnCLIP(config, logger, class_names)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b1b0a56f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[03-04 13:59:56 TCCLIP]\u001B[0m\u001B[33m(tools.py 180)\u001B[0m: INFO ==============> Resuming from C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/zero_shot_k400_tc_clip.pth....................\n",
      "\u001B[32m[03-04 13:59:56 TCCLIP]\u001B[0m\u001B[33m(tools.py 208)\u001B[0m: INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.token_prefix', 'prompt_learner.token_suffix'], unexpected_keys=[])\n",
      "\u001B[32m[03-04 13:59:56 TCCLIP]\u001B[0m\u001B[33m(tools.py 218)\u001B[0m: INFO => loaded successfully 'C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/zero_shot_k400_tc_clip.pth' (epoch 9)\n",
      "\u001B[32m[03-04 13:59:56 TCCLIP]\u001B[0m\u001B[33m(1028797808.py 4)\u001B[0m: INFO Loaded checkpoint at epoch 10 with max accuracy 81.3\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "if config.resume:\n",
    "    epoch_loaded, max_accuray_loaded = load_checkpoint(config, model, None, None, logger, model_only=True)\n",
    "    logger.info(\n",
    "            f\"Loaded checkpoint at epoch {epoch_loaded} with max accuracy {max_accuray_loaded:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc32b34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Video preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0f1f0416",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Video preprocessing pipeline\n",
    "\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
    "\n",
    "scale_resize = int(256 / 224 * config.input_size)\n",
    "collect_keys = ['imgs']\n",
    "\n",
    "val_pipeline = [\n",
    "    dict(type='DecordInit'),\n",
    "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=config.num_frames, test_mode=True),\n",
    "    dict(type='DecordDecode'),\n",
    "    dict(type='Resize', scale=(-1, scale_resize)),\n",
    "    dict(type='CenterCrop', crop_size=config.input_size),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='FormatShape', input_format='NCHW'),\n",
    "    dict(type='Collect', keys=collect_keys, meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "if config.num_crop == 3:\n",
    "    val_pipeline[3] = dict(type='Resize', scale=(-1, config.input_size))\n",
    "    val_pipeline[4] = dict(type='ThreeCrop', crop_size=config.input_size)\n",
    "if config.num_clip > 1:\n",
    "    val_pipeline[1] = dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=config.num_frames,\n",
    "                           multiview=config.num_clip)\n",
    "val_pipeline = [p for p in val_pipeline if p is not None]\n",
    "\n",
    "pipeline = Compose(val_pipeline)\n",
    "\n",
    "dict_file = {'filename': video_path, 'tar': False, 'modality': 'RGB', 'start_index': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4845ffa5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TC-CLIP inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d30fe299",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaba\\AppData\\Local\\Temp\\ipykernel_29076\\164853365.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "video = pipeline(dict_file)\n",
    "video_tensor = video['imgs'].unsqueeze(0).cuda().float() # Size: [1, T, 3, H, W]\n",
    "\n",
    "# Inference with TC-CLIP\n",
    "with torch.no_grad():\n",
    "    if config.use_torch_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(video_tensor)\n",
    "    else:\n",
    "        output = model(video_tensor)\n",
    "    \n",
    "    logits = output['logits']\n",
    "\n",
    "pred_index = logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "25d0b5a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[23.5469, 23.1562, 22.9062, 23.4531, 20.9688, 24.6094, 22.6875, 25.9844]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "For video:  C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4/walk/seq_000011.mp4\n",
      "Predicted action category is \"walking\"\n"
     ]
    }
   ],
   "source": [
    "print(f'Logits: {logits}')\n",
    "print(\"For video: \", video_path)\n",
    "print(f'Predicted action category is \"{class_names[pred_index]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc1915",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Acknowledgements: [ViFi-CLIP's repository](https://github.com/muzairkhattak/ViFi-CLIP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7423913e-a9c1-47e6-903d-8a79938639d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Running on a folder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "c20927dc-ab64-4cf3-9e3f-cea7b6344d87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[03-05 15:55:28 TCCLIP]\u001B[0m\u001B[33m(1196747461.py 44)\u001B[0m: INFO working dir: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/inference\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "from datasets.pipeline import Compose\n",
    "from trainers.build_trainer import returnCLIP\n",
    "from utils.logger import create_logger\n",
    "from utils.tools import load_checkpoint\n",
    "\n",
    "def extract_ground_truth(video_path):\n",
    "    \"\"\"Extracts the ground truth action from the video file path.\"\"\"\n",
    "    parts = Path(video_path).parts\n",
    "    for part in reversed(parts):\n",
    "        if part in class_names:\n",
    "            return part\n",
    "    return None\n",
    "\n",
    "# User-defined settings\n",
    "output = \"C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/inference\"\n",
    "tc_clip_model_path = \"C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/zero_shot_k400_tc_clip.pth\"\n",
    "class_names = ['dancing', 'jumping', 'kicking', 'kneeling', 'punching', 'running', 'throwing', 'walking']\n",
    "parent_folder = \"C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/\"\n",
    "\n",
    "# Initialize Hydra configs\n",
    "overrides = [\n",
    "    f\"output={output}\",\n",
    "    \"eval=test\",\n",
    "    \"trainer=tc_clip\",\n",
    "    f\"resume={tc_clip_model_path}\"\n",
    "]\n",
    "\n",
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    config = compose(config_name=\"zero_shot.yaml\", overrides=overrides)\n",
    "\n",
    "OmegaConf.set_struct(config, False)\n",
    "Path(config.output).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger = create_logger(output_dir=config.output, dist_rank=0, name=f\"{config.trainer_name}\")\n",
    "logger.info(f\"working dir: {config.output}\")\n",
    "\n",
    "config.use_torch_amp = torch.__version__.startswith(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9c4f1916-6b28-4bf8-9e4b-fde2465d07f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[03-05 15:55:29 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 56)\u001B[0m: INFO Loading CLIP (backbone: ViT-B/16)\n",
      "Using spatial positional embedding\n",
      "Weights not found for some missing keys:  ['visual.transformer.resblocks.1.attn.local_global_bias_table', 'visual.transformer.resblocks.2.attn.local_global_bias_table', 'visual.transformer.resblocks.3.attn.local_global_bias_table', 'visual.transformer.resblocks.4.attn.local_global_bias_table', 'visual.transformer.resblocks.5.attn.local_global_bias_table', 'visual.transformer.resblocks.6.attn.local_global_bias_table', 'visual.transformer.resblocks.7.attn.local_global_bias_table', 'visual.transformer.resblocks.8.attn.local_global_bias_table', 'visual.transformer.resblocks.9.attn.local_global_bias_table', 'visual.transformer.resblocks.10.attn.local_global_bias_table', 'visual.transformer.resblocks.11.attn.local_global_bias_table']\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 59)\u001B[0m: INFO \u001B[34m\u001B[1mBuilding TCCLIP\u001B[0m\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip_prompt_learner.py 54)\u001B[0m: INFO Video-conditional prompt learning\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip_prompt_learner.py 55)\u001B[0m: INFO Initial context: \"a photo of a\"\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip_prompt_learner.py 56)\u001B[0m: INFO Number of learnable text prompt vectors: 4\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip_text_encoder.py 96)\u001B[0m: INFO Copy CLIP transformer 11th layer weights to prompt generation layer\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip_text_encoder.py 106)\u001B[0m: INFO Prompt generation level: [11]\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip_text_encoder.py 107)\u001B[0m: INFO Prompt generation stop grad: True\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(tc_clip.py 27)\u001B[0m: INFO Using context tokens from vision layer [11]\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 97)\u001B[0m: INFO ----------------------------------------------------\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 98)\u001B[0m: INFO Freezed Parameters\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 102)\u001B[0m: INFO ----------------------------------------------------\n",
      "\u001B[32m[03-05 15:55:33 TCCLIP]\u001B[0m\u001B[33m(build_trainer.py 105)\u001B[0m: INFO Number of Parameters: 127.5M\n",
      "\u001B[32m[03-05 15:55:34 TCCLIP]\u001B[0m\u001B[33m(tools.py 180)\u001B[0m: INFO ==============> Resuming from C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/zero_shot_k400_tc_clip.pth....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaba\\OneDrive\\Desktop\\Master Thesis\\bias-action-recognition\\framework\\models\\tc-clip\\utils\\tools.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(config.resume, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[03-05 15:55:34 TCCLIP]\u001B[0m\u001B[33m(tools.py 208)\u001B[0m: INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.token_prefix', 'prompt_learner.token_suffix'], unexpected_keys=[])\n",
      "\u001B[32m[03-05 15:55:34 TCCLIP]\u001B[0m\u001B[33m(tools.py 218)\u001B[0m: INFO => loaded successfully 'C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/framework/models/tc-clip/weights/zero_shot_k400_tc_clip.pth' (epoch 9)\n",
      "\u001B[32m[03-05 15:55:34 TCCLIP]\u001B[0m\u001B[33m(890561573.py 8)\u001B[0m: INFO Loaded checkpoint at epoch 10 with max accuracy 81.3\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = returnCLIP(config, logger, class_names)\n",
    "model.cuda()\n",
    "\n",
    "# Load checkpoint\n",
    "if config.resume:\n",
    "    epoch_loaded, max_accuracy_loaded = load_checkpoint(config, model, None, None, logger, model_only=True)\n",
    "    logger.info(f\"Loaded checkpoint at epoch {epoch_loaded} with max accuracy {max_accuracy_loaded:.1f}\")\n",
    "\n",
    "# Video preprocessing pipeline\n",
    "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
    "scale_resize = int(256 / 224 * config.input_size)\n",
    "collect_keys = ['imgs']\n",
    "\n",
    "val_pipeline = [\n",
    "    dict(type='DecordInit'),\n",
    "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=config.num_frames, test_mode=True),\n",
    "    dict(type='DecordDecode'),\n",
    "    dict(type='Resize', scale=(-1, scale_resize)),\n",
    "    dict(type='CenterCrop', crop_size=config.input_size),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='FormatShape', input_format='NCHW'),\n",
    "    dict(type='Collect', keys=collect_keys, meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "pipeline = Compose(val_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "acfa3dd7-0f6a-4807-9fb2-546a506c2116",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaba\\AppData\\Local\\Temp\\ipykernel_29076\\2088387876.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000001.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000005.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000040.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000042.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000043.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000068.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000076.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000104.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000126.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\dancing\\seq_000135.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\jumping\\seq_000030.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\jumping\\seq_000051.mp4 | Ground Truth: jumping | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\jumping\\seq_000083.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\jumping\\seq_000093.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\jumping\\seq_000096.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kicking\\seq_000014.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kicking\\seq_000062.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kicking\\seq_000064.mp4 | Ground Truth: kicking | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kicking\\seq_000112.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kneeling\\seq_000000.mp4 | Ground Truth: kneeling | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kneeling\\seq_000025.mp4 | Ground Truth: kneeling | Predicted: kneeling |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kneeling\\seq_000078.mp4 | Ground Truth: kneeling | Predicted: kneeling |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kneeling\\seq_000084.mp4 | Ground Truth: kneeling | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\kneeling\\seq_000109.mp4 | Ground Truth: kneeling | Predicted: kneeling |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\punching\\seq_000017.mp4 | Ground Truth: punching | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\punching\\seq_000077.mp4 | Ground Truth: punching | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\running\\seq_000009.mp4 | Ground Truth: running | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\running\\seq_000010.mp4 | Ground Truth: running | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\running\\seq_000026.mp4 | Ground Truth: running | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\running\\seq_000067.mp4 | Ground Truth: running | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\throwing\\seq_000130.mp4 | Ground Truth: throwing | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\walking\\seq_000034.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\walking\\seq_000045.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\walking\\seq_000066.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_a_mp4\\walking\\seq_000087.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\dancing\\seq_000111.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000002.mp4 | Ground Truth: jumping | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000022.mp4 | Ground Truth: jumping | Predicted: running |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000032.mp4 | Ground Truth: jumping | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000083.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000084.mp4 | Ground Truth: jumping | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000088.mp4 | Ground Truth: jumping | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000099.mp4 | Ground Truth: jumping | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000109.mp4 | Ground Truth: jumping | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000110.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000120.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\jumping\\seq_000121.mp4 | Ground Truth: jumping | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\kicking\\seq_000024.mp4 | Ground Truth: kicking | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\kicking\\seq_000045.mp4 | Ground Truth: kicking | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\kicking\\seq_000097.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\kicking\\seq_000127.mp4 | Ground Truth: kicking | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\punching\\seq_000131.mp4 | Ground Truth: punching | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\running\\seq_000007.mp4 | Ground Truth: running | Predicted: walking |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\running\\seq_000008.mp4 | Ground Truth: running | Predicted: running |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\running\\seq_000128.mp4 | Ground Truth: running | Predicted: running |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\throwing\\seq_000036.mp4 | Ground Truth: throwing | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\throwing\\seq_000057.mp4 | Ground Truth: throwing | Predicted: throwing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000001.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000011.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000013.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000025.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000026.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000034.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000043.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000063.mp4 | Ground Truth: walking | Predicted: running |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000077.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000092.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000102.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000107.mp4 | Ground Truth: walking | Predicted: running |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221011_1_250_batch01hand_closeup_suburb_d_mp4\\walking\\seq_000129.mp4 | Ground Truth: walking | Predicted: walking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\dancing\\seq_000031.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\dancing\\seq_000071.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\dancing\\seq_000083.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\dancing\\seq_000096.mp4 | Ground Truth: dancing | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\dancing\\seq_000105.mp4 | Ground Truth: dancing | Predicted: throwing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\dancing\\seq_000133.mp4 | Ground Truth: dancing | Predicted: dancing |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000000.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000005.mp4 | Ground Truth: jumping | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000014.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000054.mp4 | Ground Truth: jumping | Predicted: throwing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000066.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000077.mp4 | Ground Truth: jumping | Predicted: throwing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000078.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000080.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000090.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000094.mp4 | Ground Truth: jumping | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\jumping\\seq_000108.mp4 | Ground Truth: jumping | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\kicking\\seq_000017.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\kicking\\seq_000026.mp4 | Ground Truth: kicking | Predicted: kicking |  MATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\kicking\\seq_000061.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\kicking\\seq_000062.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\kicking\\seq_000088.mp4 | Ground Truth: kicking | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\kicking\\seq_000098.mp4 | Ground Truth: kicking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\punching\\seq_000008.mp4 | Ground Truth: punching | Predicted: throwing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\punching\\seq_000093.mp4 | Ground Truth: punching | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\punching\\seq_000097.mp4 | Ground Truth: punching | Predicted: throwing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\running\\seq_000006.mp4 | Ground Truth: running | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\running\\seq_000063.mp4 | Ground Truth: running | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\running\\seq_000065.mp4 | Ground Truth: running | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\running\\seq_000073.mp4 | Ground Truth: running | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\throwing\\seq_000041.mp4 | Ground Truth: throwing | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\throwing\\seq_000091.mp4 | Ground Truth: throwing | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\throwing\\seq_000132.mp4 | Ground Truth: throwing | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000010.mp4 | Ground Truth: walking | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000021.mp4 | Ground Truth: walking | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000027.mp4 | Ground Truth: walking | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000035.mp4 | Ground Truth: walking | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000038.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000047.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000060.mp4 | Ground Truth: walking | Predicted: kneeling |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000079.mp4 | Ground Truth: walking | Predicted: dancing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000119.mp4 | Ground Truth: walking | Predicted: throwing |  MISMATCH\n",
      "Video: C:/Users/anaba/OneDrive/Desktop/Master Thesis/bias-action-recognition/bedlam/be_imagedata_download/categorized/20221012_1_500_batch01hand_closeup_highSchoolGym_mp4\\walking\\seq_000131.mp4 | Ground Truth: walking | Predicted: kneeling |  MISMATCH\n"
     ]
    }
   ],
   "source": [
    "# Process all videos in parent folder\n",
    "correct_predictions = 0\n",
    "total_videos = 0\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "\n",
    "for root, _, files in os.walk(parent_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(root, file)\n",
    "            ground_truth = extract_ground_truth(video_path)\n",
    "            if not ground_truth:\n",
    "                continue\n",
    "            \n",
    "            total_videos += 1\n",
    "            dict_file = {'filename': video_path, 'tar': False, 'modality': 'RGB', 'start_index': 0}\n",
    "            video = pipeline(dict_file)\n",
    "            video_tensor = video['imgs'].unsqueeze(0).cuda().float()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                if config.use_torch_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        output = model(video_tensor)\n",
    "                else:\n",
    "                    output = model(video_tensor)\n",
    "                logits = output['logits']\n",
    "            \n",
    "            pred_index = logits.argmax(-1).item()\n",
    "            predicted_label = class_names[pred_index]\n",
    "            \n",
    "            ground_truths.append(ground_truth)\n",
    "            predictions.append(predicted_label)\n",
    "            \n",
    "            match = \" MATCH\" if predicted_label == ground_truth else \" MISMATCH\"\n",
    "            if predicted_label == ground_truth:\n",
    "                correct_predictions += 1\n",
    "            \n",
    "            print(f'Video: {video_path} | Ground Truth: {ground_truth} | Predicted: {predicted_label} | {match}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f2c1e735-bd4c-4b6d-8f4a-46e662b3c835",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 29.20% (33/113)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and print overall accuracy\n",
    "accuracy = (correct_predictions / total_videos) * 100 if total_videos > 0 else 0\n",
    "print(f'Overall Accuracy: {accuracy:.2f}% ({correct_predictions}/{total_videos})')\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(ground_truths, predictions, labels=class_names)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix of TC-CLIP Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034f321-1680-4591-9c79-8e79b244efde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}